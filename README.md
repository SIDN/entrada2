# ENTRADA2

A tool for converting DNS network data to [Apache Parquet](https://parquet.apache.org/) format and make it available for analysis using an [Apache Iceberg](https://iceberg.apache.org/) table.   
ENTRADA2 is an improvement on [ENTRADA](https://github.com/SIDN/entrada) and is designed to be more performent, scalable and to reduce the output size of the generated Parquet data.
Due to these changes, data generated by ENTRADA2 uses a different table schema and is NOT compatible with the original ENTRADA table schema.


Based on the following components:  

- S3 storage (MinIO, AWS)
- Messaging Queue ( RabbitMQ, AWS SQS)
- Metadata Data catalog (AWS Glue or [REST based Iceberg catalog server](https://github.com/SIDN/iceberg-rest-catalog-server) + PostgreSQL)
- Metrics (InfluxDB)
- Query engine (Trino, AWS Athena, Spark)

List of changes:

- Removed Hadoop support
- Improved sopport for s3 object storage
- Added support for Kubernetes
- Added support for Apache Iceberg
- The qname column only contains the labels preceding the domainname
- Rows are now sorted by domainname for more efficient compression
- Default column compression changed to gzip, was Snappy
- Use small Parquet max dictionary size, to prevent domainname column using dict
- Use bloomfilter for domainname column, performance boost when filtering on domainname 
- Renamed table columns to indicate protocol
- Removed unused columns
- No longer required to coinfgure name server, container can handle any pcap
- No longer storing state between pcaps, might cause some unmatched packets
- Added event based workflow, started after uploading pcap to s3
- Added API to control containers, e.g. start/stop processing


The following deployment modes are supported:
- Docker (best for test and evaluation)
- Kubernetes
- AWS cloud

# Build

```
mvn package
docker build --tag=sidnlabs/entrada2:0.0.1 .
docker push sidnlabs/entrada2:0.0.1
```

# Getting started

If you want to get started, an easy method is by using the [Docker Compose script](https://github.com/SIDN/entrada2/blob/main/docker/docker-compose.yml) to create a test
environment containing all the required components, using default configuration settings.
ENTRADA2 uses the [Maxmind](https://www.maxmind.com) GeoIP2 database, if you have a license then set the MAXMIND_LICENSE_PAID
environment variable, otherwise signup for the free [GeoLite2](https://dev.maxmind.com/geoip/geolite2-free-geolocation-data ) database and use 
the MAXMIND_LICENSE_FREE environment variable.

Example using the Maxmind GeoIP2 database:

```
export MAXMIND_LICENSE_PAID=<your-key-here>
docker-compose --profile test up
```

## Uploading pcap file
When all components have started up, you may upload a pcap file to s3 and processing of the file will start automatically.  
The default bucket name is `sidnlabs-iceberg-data` and pcap files need to be uploaded in the directory `pcap/`.

Use the the following s3 tags when uploading file to S3:

- entrada-ns-server: Logical name of the name server
- entrada-ns-anycast-site: Anycast site of the name server

Example using MinIO:  

```

mc cp --tags "entrada-ns-server=ns1.example.nl&entrada-ns-anycast-site=ams"  \
ams-ns1-150_2023-10-04-11:09:51.pcap.gz minio/sidnlabs-iceberg-data/pcap/ams-ns1-150_2023-10-04-11:09:51.pcap.gz
```


## Analysing results
The results may be analysed using different tools, such as AWS Athena, Trino or Apache Spark. 
The Docker Compose script automaticlly starts Trino, for quickly analysing a limited dataset.  

Example using the Trino commandline client (installed in Trino container):

```
docker exec -it docker-trino-1 trino
```

Switch to the correct catalog:

```
use iceberg_entrada.entrada2
```

Query data in dns table:

```
select count(1) from dns;
```

## Cleanup
To cleanup the test evironment, stop the Docker containers, delete the Docker volumes and restart the containers.

```
docker system prune -f
docker volume rm docker_dataVolume
docker volume rm docker_pgVolume
docker-compose --profile test up
```


## API

TODO


## Running multiple containers

TODO


## Components UI
Some of the components provide a web interface, below are the URLs for the components started by the docker compose script.
Login credentials can be found in the script.

- [MinIO](http://localhost:9000)
- [RabbitMQ](http://localhost:15672/)
- [InfluxDB](http://localhost:8086/)
- [Trino](http://localhost:8085/) 
